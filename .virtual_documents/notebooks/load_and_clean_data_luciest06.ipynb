#Structure:
#Import librairies
#Import table/data
    #challenge: #file had metadata/explanations in the first 5 rows, which made the file irregular and caused an error (An error occurred: Error tokenizing data. C error: Expected 3 fields in line 5, saw 69) during the import
#quick cleaning of column names
#removing unwanted columns: because there are many, creation of a list to gather all the ones we need removed
#adding average column
#removing columns used for the calculation of average column and not needed anymore
#importing second dataset to add countries income group (high vs. low income)
#selecting only countries we want to analyze



import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

unpaid_dom_work_URL = '../data/raw/API_SG.TIM.UWRK.FE_DS2_en_csv_v2_3435778.csv'

try:
    unpaid_dom_work_df = pd.read_csv(unpaid_dom_work_URL)
    print("File loaded successfully!")
    print(unpaid_dom_work_df.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

#file had metadata/explanations in the first 5 rows, which made the file irregular and caused an error (An error occurred: Error tokenizing data. C error: Expected 3 fields in line 5, saw 69) during the import




unpaid_dom_work_df.shape


#quick cleaning of column names
unpaid_dom_work_df.columns=[x.lower() for x in unpaid_dom_work_df.columns]
unpaid_dom_work_df.columns=[x.strip() for x in unpaid_dom_work_df.columns]
unpaid_dom_work_df.columns=map(lambda x:x.replace(" ","_"),unpaid_dom_work_df.columns)


#removing unwanted columns: because there are many, creation of a list to gather all the ones we need removed

list_years_to_remove=[1960]
year=1960
for i in range(39):
    year+=1
    list_years_to_remove.append(year)
print(list_years_to_remove)

for x in list_years_to_remove:
    unpaid_dom_work_df.drop(str(x), axis=1, inplace=True)

unpaid_dom_work_df.drop('unnamed:_68',axis=1,inplace=True)
unpaid_dom_work_df.drop('indicator_code',axis=1,inplace=True)


unpaid_dom_work_df.head()



#adding average column

list_years_for_average=[2000]
year_average=2000
for y in range(23):
    year_average+=1
    list_years_for_average.append(year_average)

list_years_for_average_str=[]
for z in list_years_for_average:
    z=str(z)
    list_years_for_average_str.append(z)


unpaid_dom_work_df['average_since_2000']=unpaid_dom_work_df[list_years_for_average_str].mean(axis=1)
unpaid_dom_work_df.head()

unpaid_dom_work_df['average_since_2000'].isna()
unpaid_dom_work_df['average_since_2000'].value_counts()

print(unpaid_dom_work_df.iloc[263])
unpaid_dom_work_df.head()

unpaid_dom_work_df['average_since_2000'].isna().sum() #We have 177 missing average out of 266 rows
unpaid_dom_work_df['average_since_2000'].isna().sum()/unpaid_dom_work_df.shape[0] # 67% missing values

unpaid_dom_work_df.head()

#removing columns used for the calculation of average column and not needed anymore
unpaid_dom_work_df.drop(columns=list_years_for_average_str,axis=1, inplace=True)



#importing second dataset to add countries income group (high vs. low income)

unpaid_dom_work_URL_grouped_incometype = '../data/raw/Metadata_Country_API_SG.TIM.UWRK.FE_DS2_en_csv_v2_3435778.csv'

try:
    unpaid_dom_work_incometype_df = pd.read_csv(unpaid_dom_work_URL_grouped_incometype)
    print("File loaded successfully!")
    print(unpaid_dom_work_incometype_df.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

unpaid_dom_work_incometype_df.shape


#keeping only columns we need

unpaid_dom_work_incometype_df=unpaid_dom_work_incometype_df[['Country Code','Region','IncomeGroup']]

#quick cleaning of column names
unpaid_dom_work_incometype_df.columns=[x.lower() for x in unpaid_dom_work_incometype_df.columns]
unpaid_dom_work_incometype_df.columns=[x.strip() for x in unpaid_dom_work_incometype_df.columns]
unpaid_dom_work_incometype_df.columns=map(lambda x:x.replace(" ","_"),unpaid_dom_work_incometype_df.columns)

unpaid_dom_work_incometype_df



#merge of both data set on the country_code common column

unpaid_dom_work_merged_df=pd.merge(unpaid_dom_work_df, unpaid_dom_work_incometype_df, how='inner', on='country_code')
unpaid_dom_work_merged_df


#selecting only countries we want to analyze

unpaid_dom_work_merged_df_test = unpaid_dom_work_merged_df[unpaid_dom_work_merged_df['country_name'].isin(['France', 'Germany','Norway','Greece','Brazil','United States','Colombia','Japan','New Zealand','Pakistan','Ghana','Cameroon'])]
unpaid_dom_work_merged_df_test= unpaid_dom_work_merged_df_test.reset_index()
unpaid_dom_work_merged_df_test


# Import excel file on HDI (Human Development Index)

HDI_file_path = "../data/raw/HDI.csv"

df_HDI = pd.read_csv(HDI_file_path,usecols = ['ISO3','Country','Continent','HDI Rank (2021)','Labour force participation rate, female (% ages 15 and older) (2017)','Labour force participation rate, female (% ages 15 and older) (2018)','Labour force participation rate, female (% ages 15 and older) (2019)','Labour force participation rate, female (% ages 15 and older) (2020)','Labour force participation rate, female (% ages 15 and older) (2021)'])
display(df_HDI)

# renaming the columns for better readability
df_HDI =df_HDI.rename(columns={
    'Labour force participation rate, female (% ages 15 and older) (2017)': 'lpf_2017_%',
    'Labour force participation rate, female (% ages 15 and older) (2018)': 'lpf_2018_%',
    'Labour force participation rate, female (% ages 15 and older) (2019)': 'lpf_2019_%',
    'Labour force participation rate, female (% ages 15 and older) (2020)': 'lpf_2020_%',
    'Labour force participation rate, female (% ages 15 and older) (2021)': 'lpf_2021_%'
})
display(df_HDI)



def filter_by_country(df, country_list):
    """Filter the DataFrame to include only rows where the 'Country' column matches a value in the provided country list.
    country_list (list): A list of countries to filter the DataFrame by.
    Returns:
    pd.DataFrame: A DataFrame containing only the rows where the 'Country' matches a value in the country list."""
    filtered_HDI_df = df_HDI[df_HDI['Country'].isin(country_list)]
    return filtered_HDI_df

# List of countries to filter by
countries_to_filter = ['Norway', 'Greece','France','Germany','United States','Brazil','Colombia','Japan','New Zealand','Pakistan','Ghana','Cameroon']

# Call the function with the DataFrame and the list of countries
df_HDI = filter_by_country(df_HDI, countries_to_filter)

# Display the filtered DataFrame
display(df_HDI)


df_HDI.reset_index( drop=True , inplace = True)
display(df_HDI)


df_HDI = df_HDI.sort_values(by='HDI Rank (2021)', ascending=True) # Set ascending=False for descending order

df_HDI.reset_index( drop=True , inplace = True)

#updating column name to match with the domestic unpaid work dataframe before merging both
df_HDI= df_HDI.rename(columns={'ISO3': 'country_code'})
df_HDI


#Merge HDI and Unpaid domestic work dataframes

merged_HDI_unpaid_dom_work_df=pd.merge(df_HDI, unpaid_dom_work_df, on='country_code', how='inner')
merged_HDI_unpaid_dom_work_df 


merged_HDI_unpaid_dom_work_df.describe()


#merged_HDI_unpaid_dom_work_df.columns
merged_HDI_unpaid_dom_work_df[['average_since_2000','HDI Rank (2021)']].corr()


# read the excel file and make the data frame, select the columns we need.

#challenge: didn't have libraray to read the excel. needed to install the library openpyxl

# Import excel file on Gender Equality in the Economy

gender_eco_file_path = "../data/raw/WORLD_Dataset_Gender_Equality_in_the_Economy_5.19.23.xlsx"

try:
    df_gd_economy = pd.read_excel(gender_eco_file_path, usecols=(["country", "iso2", "iso3", "region", "wb_econ","sum_gender","hir_gender","pay_gender","anyprotect_preg","disc_edu","sh_covered","term_gender", "disc_propose", "maternal_leave", "paternal_leave", "mtlv_min_wrr_ilo", "mtlv_job_protect", "maternal_self", "anylv_ch_evday", "finbar", "compend", "disc_sex_prim", "minage_fem_leg"]))
    print("File loaded successfully!")
    print(df_gd_economy.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")


def replace_nulls_conditionally(df_gd_economy, columns, threshold=10, other_value='Unknown'):
    """ Replacing the null values in the columns by the top value if the column has less than 10 missing values, 
    if not the column has 10 or more missing values they are replaced by Unknown """
    df_gd_economy2 = df_gd_economy.copy()
    for column in columns:
         null_count = df_gd_economy2[column].isna().sum()
         if null_count < threshold:
             top_value = df_gd_economy2[column].mode()[0]
             df_gd_economy2[column] = df_gd_economy2[column].fillna(top_value)
         else:
             df_gd_economy2[column] = df_gd_economy2[column].fillna(other_value)
             
    return df_gd_economy2

df_gd_economy = replace_nulls_conditionally(df_gd_economy, ['maternal_self', 'finbar','compend','sh_covered'])
print("\nUpdated DataFrame:")
display(df_gd_economy)


#checking missing values per column
df_gd_economy.isna().sum()

#finding which row has the missing value for column iso2
df_gd_economy_filtered = df_gd_economy[(df_gd_economy['iso2'].isna() == True) & (df_gd_economy['iso3'].isna() == False)]
df_gd_economy_filtered

#replacing the missing value by the accurate value (iso2 code of Namibia)
df_gd_economy['iso2'] = df_gd_economy['iso2'].fillna('NA')


#renaming columns

df_gd_economy1 = df_gd_economy.rename (columns = {'sum_gender': 'gd_ban' ,
       'hir_gender':'gd_hiring_ban', 'pay_gender':'g_equal_pay_guarantee', 'term_gender':'gd_termination_ban', 
        'anyprotect_preg' : 'preg_discrimination_ban' , 
         'disc_edu' : 'gd_prevention_body', 'disc_propose':'gd_policy_body',
       'maternal_leave':'ml_paid', 'paternal_leave': 'pl_paid', 'mtlv_min_wrr_ilo' : 'lowest_wage_replacement_paid_leave_mothers',
       'mtlv_job_protect' :'ml_job_protection', 'maternal_self': 'ml_self_employed_paid' , 'anylv_ch_evday' :'parental_leave_child_health', 
        'finbar' : 'tuition_free_education_policy','compend' : ' compulsory_education_policy', 
        'disc_sex_prim': 'gd_ban_education', 'iso3': 'country_code'})

df_gd_economy1


#filtering by country

df_gd_economy2 = df_gd_economy1[df_gd_economy1['country'].isin(['United States of America', 'New Zealand', 'Germany', 'Japan', 
                                     'Pakistan', 'Norway', 'France', 'Greece', 
                                     'Brazil', 'Colombia', 'Ghana', 'Cameroon'])]
df_gd_economy2


# reset row index keeping the old index as a coulumn
df_gd_economy2_reset = df_gd_economy2.reset_index()
df_gd_economy2_reset


#merging the third table to the first two tables already merged

merged_gdeco_HDI_unpaiddomwork_df=pd.merge(merged_HDI_unpaid_dom_work_df, df_gd_economy2, on='country_code', how='inner')
merged_gdeco_HDI_unpaiddomwork_df


merged_gdeco_HDI_unpaiddomwork_df['GDP_per_capita']=merged_gdeco_HDI_unpaiddomwork_df['country_code'].map({'NOR':36.5,'GRC':11.07,'FRA':18.7,'DEU':21.25,'USA':30.58,'BRA':3.03,'COL':3.05,'JPN':17.19,'NZL':26.29,'PAK':0.35,'GHA':0.63,'CMR':0.45})

merged_gdeco_HDI_unpaiddomwork_df



merged_gdeco_HDI_unpaiddomwork_df[['GDP_per_capita','average_since_2000','lpf_2021_%','HDI Rank (2021)','gd_ban','gd_hiring_ban','g_equal_pay_guarantee','gd_termination_ban', 'preg_discrimination_ban','gd_prevention_body','gd_policy_body','ml_paid', 'pl_paid','lowest_wage_replacement_paid_leave_mothers','ml_job_protection','ml_self_employed_paid','parental_leave_child_health', 'tuition_free_education_policy',' compulsory_education_policy','gd_ban_education']].corr()





sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='lpf_2021_%')
#correlation is 0.28
#there is actually a higher correlation when we exclude countries with low GDP

#Testing when the 3 lowest GDP countries are removed

display(merged_gdeco_HDI_unpaiddomwork_df[merged_gdeco_HDI_unpaiddomwork_df["GDP_per_capita"]>3][['GDP_per_capita','lpf_2021_%']].corr())
LFP_GDP_corr_plot = sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df[merged_gdeco_HDI_unpaiddomwork_df["GDP_per_capita"]>3],x='GDP_per_capita',y='lpf_2021_%')


#adding a regression line in the plot
sns.regplot(x='GDP_per_capita',y='lpf_2021_%',data=merged_gdeco_HDI_unpaiddomwork_df[merged_gdeco_HDI_unpaiddomwork_df["GDP_per_capita"]>3],scatter=False,color='orange',ci=None)

#switching titles of the plot
plt.title('Correlation between GDP per Capita and Female Labor Force Participation (2021)')
plt.xlabel('GDP per Capita (2021)')
plt.ylabel('Female Labor Force Participation in % (2021)')


plt.savefig('LFP_GDP_corr_plot.png', format='png', dpi=300)



HDI_GDP_corr_plot=sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='HDI Rank (2021)')
#For the year 2021, there is an exponential correlation between a country's GDP per capita and its HDI rank.
#The higher the HDI Rank, the lower the GDP per capita
#Strong negative correlation -0.87

#switching titles of the plot
plt.title('Correlation between GDP per Capita and HDI Rank')
plt.xlabel('GDP per Capita (2021)')
plt.ylabel('HDI Rank (2021)')


plt.savefig('HDI_GDP_corr_plot.png', format='png', dpi=300)



sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='gd_prevention_body')



sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='average_since_2000') 


#independent body responsible for education, awareness, and advocacy to prevent workplace gender discrimination

GD_prevention_body_GDP_corr_plot=sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='gd_prevention_body')

#switching titles of the plot
plt.xlabel('GDP per Capita (2021)')
plt.ylabel('Independent body for workplace gender discrimination')


plt.savefig('gd_prevention_body_GDP_corr_plot.png', format='png', dpi=300)



#gd_policy_body
#Is there an independent body responsible for proposing legislation or policies to prevent workplace gender discrimination?

GD_policy_body_GDP_corr_plot=sns.scatterplot(data=merged_gdeco_HDI_unpaiddomwork_df,x='GDP_per_capita',y='gd_policy_body')

#switching titles of the plot
plt.xlabel('GDP per Capita (2021)')
plt.ylabel('Independent body for reg. on gender discrimination')


plt.savefig('gd_regulation_body_GDP_corr_plot.png', format='png', dpi=300)




