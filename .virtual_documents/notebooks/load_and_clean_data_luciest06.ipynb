#Structure:
#Import librairies
#Import table/data
    #challenge: #file had metadata/explanations in the first 5 rows, which made the file irregular and caused an error (An error occurred: Error tokenizing data. C error: Expected 3 fields in line 5, saw 69) during the import
#quick cleaning of column names
#removing unwanted columns: because there are many, creation of a list to gather all the ones we need removed
#adding average column
#removing columns used for the calculation of average column and not needed anymore
#importing second dataset to add countries income group (high vs. low income)
#selecting only countries we want to analyze



import pandas as pd
import numpy as np


unpaid_dom_work_URL = '../data/raw/API_SG.TIM.UWRK.FE_DS2_en_csv_v2_3435778.csv'

try:
    unpaid_dom_work_df = pd.read_csv(unpaid_dom_work_URL)
    print("File loaded successfully!")
    print(unpaid_dom_work_df.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

#file had metadata/explanations in the first 5 rows, which made the file irregular and caused an error (An error occurred: Error tokenizing data. C error: Expected 3 fields in line 5, saw 69) during the import




unpaid_dom_work_df.shape


#quick cleaning of column names
unpaid_dom_work_df.columns=[x.lower() for x in unpaid_dom_work_df.columns]
unpaid_dom_work_df.columns=[x.strip() for x in unpaid_dom_work_df.columns]
unpaid_dom_work_df.columns=map(lambda x:x.replace(" ","_"),unpaid_dom_work_df.columns)


#removing unwanted columns: because there are many, creation of a list to gather all the ones we need removed

list_years_to_remove=[1960]
year=1960
for i in range(39):
    year+=1
    list_years_to_remove.append(year)
print(list_years_to_remove)

for x in list_years_to_remove:
    unpaid_dom_work_df.drop(str(x), axis=1, inplace=True)

unpaid_dom_work_df.drop('unnamed:_68',axis=1,inplace=True)
unpaid_dom_work_df.drop('indicator_code',axis=1,inplace=True)


unpaid_dom_work_df.head()



#adding average column

list_years_for_average=[2000]
year_average=2000
for y in range(23):
    year_average+=1
    list_years_for_average.append(year_average)

list_years_for_average_str=[]
for z in list_years_for_average:
    z=str(z)
    list_years_for_average_str.append(z)


unpaid_dom_work_df['average_since_2000']=unpaid_dom_work_df[list_years_for_average_str].mean(axis=1)
unpaid_dom_work_df.head()

unpaid_dom_work_df['average_since_2000'].isna()
unpaid_dom_work_df['average_since_2000'].value_counts()

print(unpaid_dom_work_df.iloc[263])
unpaid_dom_work_df.head()

unpaid_dom_work_df['average_since_2000'].isna().sum() #We have 177 missing average out of 266 rows
unpaid_dom_work_df['average_since_2000'].isna().sum()/unpaid_dom_work_df.shape[0] # 67% missing values

unpaid_dom_work_df.head()

#removing columns used for the calculation of average column and not needed anymore
unpaid_dom_work_df.drop(columns=list_years_for_average_str,axis=1, inplace=True)



#importing second dataset to add countries income group (high vs. low income)

unpaid_dom_work_URL_grouped_incometype = '../data/raw/Metadata_Country_API_SG.TIM.UWRK.FE_DS2_en_csv_v2_3435778.csv'

try:
    unpaid_dom_work_incometype_df = pd.read_csv(unpaid_dom_work_URL_grouped_incometype)
    print("File loaded successfully!")
    print(unpaid_dom_work_incometype_df.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")

unpaid_dom_work_incometype_df.shape


#keeping only columns we need

unpaid_dom_work_incometype_df=unpaid_dom_work_incometype_df[['Country Code','Region','IncomeGroup']]

#quick cleaning of column names
unpaid_dom_work_incometype_df.columns=[x.lower() for x in unpaid_dom_work_incometype_df.columns]
unpaid_dom_work_incometype_df.columns=[x.strip() for x in unpaid_dom_work_incometype_df.columns]
unpaid_dom_work_incometype_df.columns=map(lambda x:x.replace(" ","_"),unpaid_dom_work_incometype_df.columns)

unpaid_dom_work_incometype_df



#merge of both data set on the country_code common column

unpaid_dom_work_merged_df=pd.merge(unpaid_dom_work_df, unpaid_dom_work_incometype_df, how='inner', on='country_code')
unpaid_dom_work_merged_df


#selecting only countries we want to analyze

unpaid_dom_work_merged_df_test = unpaid_dom_work_merged_df[unpaid_dom_work_merged_df['country_name'].isin(['France', 'Germany','Norway','Greece','Brazil','United States','Colombia','Japan','New Zealand','Pakistan','Ghana','Cameroon'])]
unpaid_dom_work_merged_df_test= unpaid_dom_work_merged_df_test.reset_index()
unpaid_dom_work_merged_df_test


# Import excel file on HDI (Human Development Index)

HDI_file_path = "../data/raw/HDI.csv"

df_HDI = pd.read_csv(HDI_file_path,usecols = ['ISO3','Country','Continent','HDI Rank (2021)','Labour force participation rate, female (% ages 15 and older) (2017)','Labour force participation rate, female (% ages 15 and older) (2018)','Labour force participation rate, female (% ages 15 and older) (2019)','Labour force participation rate, female (% ages 15 and older) (2020)','Labour force participation rate, female (% ages 15 and older) (2021)'])
display(df_HDI)

# renaming the columns for better readability
df_HDI =df_HDI.rename(columns={
    'Labour force participation rate, female (% ages 15 and older) (2017)': 'lpf_2017_%',
    'Labour force participation rate, female (% ages 15 and older) (2018)': 'lpf_2018_%',
    'Labour force participation rate, female (% ages 15 and older) (2019)': 'lpf_2019_%',
    'Labour force participation rate, female (% ages 15 and older) (2020)': 'lpf_2020_%',
    'Labour force participation rate, female (% ages 15 and older) (2021)': 'lpf_2021_%'
})
display(df_HDI)



def filter_by_country(df, country_list):
    """Filter the DataFrame to include only rows where the 'Country' column matches a value in the provided country list.
    country_list (list): A list of countries to filter the DataFrame by.
    Returns:
    pd.DataFrame: A DataFrame containing only the rows where the 'Country' matches a value in the country list."""
    filtered_HDI_df = df_HDI[df_HDI['Country'].isin(country_list)]
    return filtered_HDI_df

# List of countries to filter by
countries_to_filter = ['Norway', 'Greece','France','Germany','United States','Brazil','Colombia','Japan','New Zealand','Pakistan','Ghana','Cameroon']

# Call the function with the DataFrame and the list of countries
df_HDI = filter_by_country(df_HDI, countries_to_filter)

# Display the filtered DataFrame
display(df_HDI)


df_HDI.reset_index( drop=True , inplace = True)
display(df_HDI)


df_HDI = df_HDI.sort_values(by='HDI Rank (2021)', ascending=True) # Set ascending=False for descending order

df_HDI.reset_index( drop=True , inplace = True)

#updating column name to match with the domestic unpaid work dataframe before merging both
df_HDI= df_HDI.rename(columns={'ISO3': 'country_code'})
df_HDI


#Merge HDI and Unpaid domestic work dataframes

merged_HDI_unpaid_dom_work_df=pd.merge(df_HDI, unpaid_dom_work_df, on='country_code', how='inner')
merged_HDI_unpaid_dom_work_df 


merged_HDI_unpaid_dom_work_df.describe()


#merged_HDI_unpaid_dom_work_df.columns
merged_HDI_unpaid_dom_work_df[['average_since_2000','HDI Rank (2021)']].corr()


# read the excel file and make the data frame, select the columns we need.

#challenge: didn't have libraray to read the excel. needed to install the library openpyxl

# Import excel file on Gender Equality in the Economy

gender_eco_file_path = "../data/raw/WORLD_Dataset_Gender_Equality_in_the_Economy_5.19.23.xlsx"

try:
    df_gd_economy = pd.read_excel(gender_eco_file_path, usecols=(["country", "iso2", "iso3", "region", "wb_econ","sum_gender","hir_gender","pay_gender","anyprotect_gender","anyprotect_preg","disc_edu","sh_covered","term_gender", "disc_propose", "maternal_leave", "paternal_leave", "mtlv_min_wrr_ilo", "mtlv_job_protect", "maternal_self", "anylv_ch_evday", "finbar", "compend", "disc_sex_prim", "minage_fem_leg"]))
    print("File loaded successfully!")
    print(df_gd_economy.head())  # Display the first few rows
except FileNotFoundError:
    print("File not found. Please check the file path.")
except Exception as e:
    print(f"An error occurred: {e}")


def replace_nulls_conditionally(df_gd_economy, columns, threshold=10, other_value='Unknown'):
    """ Replacing the null values in the columns by the top value if the column has less than 10 missing values, 
    if not the column has 10 or more missing values they are replaced by Unknown """
    df_gd_economy2 = df_gd_economy.copy()
    for column in columns:
         null_count = df_gd_economy2[column].isna().sum()
         if null_count < threshold:
             top_value = df_gd_economy2[column].mode()[0]
             df_gd_economy2[column] = df_gd_economy2[column].fillna(top_value)
         else:
             df_gd_economy2[column] = df_gd_economy2[column].fillna(other_value)
             
    return df_gd_economy2

df_gd_economy = replace_nulls_conditionally(df_gd_economy, ['maternal_self', 'finbar','compend','sh_covered'])
print("\nUpdated DataFrame:")
display(df_gd_economy)


#checking missing values per column
df_gd_economy.isna().sum()

#finding which row has the missing value for column iso2
df_gd_economy_filtered = df_gd_economy[(df_gd_economy['iso2'].isna() == True) & (df_gd_economy['iso3'].isna() == False)]
df_gd_economy_filtered

#replacing the missing value by the accurate value (iso2 code of Namibia)
df_gd_economy['iso2'] = df_gd_economy['iso2'].fillna('NA')


#renaming columns

df_gd_economy1 = df_gd_economy.rename (columns = {'sum_gender': 'gd_ban' ,
       'hir_gender':'gd_hiring_ban', 'pay_gender':'g_equal_pay_guarantee', 'term_gender':'gd_termination_ban', 
        'anyprotect_gender': 'gd_ban_law', 'anyprotect_preg' : 'preg_discrimination_ban' , 
         'disc_edu' : 'gd_prevention_body', 'disc_propose':'gd_policy_body',
       'maternal_leave':'ml_paid', 'paternal_leave': 'pl_paid', 'mtlv_min_wrr_ilo' : 'lowest_wage_replacement_paid_leave_mothers',
       'mtlv_job_protect' :'ml_job_protection', 'maternal_self': 'ml_self_employed_paid' , 'anylv_ch_evday' :'parental_leave_child_health', 
        'finbar' : 'tuition_free_education_policy','compend' : ' compulsory_education_policy', 
        'disc_sex_prim': 'gd_ban_education', 'iso3': 'country_code'})

df_gd_economy1


#filtering by country

df_gd_economy2 = df_gd_economy1[df_gd_economy1['country'].isin(['United States of America', 'New Zealand', 'Germany', 'Japan', 
                                     'Pakistan', 'Norway', 'France', 'Greece', 
                                     'Brazil', 'Colombia', 'Ghana', 'Cameroon'])]
df_gd_economy2


# reset row index keeping the old index as a coulumn
df_gd_economy2_reset = df_gd_economy2.reset_index()
df_gd_economy2_reset


#merging the third table to the first two tables already merged

merged_gdeco_HDI_unpaiddomwork_df=pd.merge(merged_HDI_unpaid_dom_work_df, df_gd_economy2, on='country_code', how='inner')
merged_gdeco_HDI_unpaiddomwork_df


merged_gdeco_HDI_unpaiddomwork_df['GDP_per_capita']=merged_gdeco_HDI_unpaiddomwork_df['country_code'].map({'NOR':36.5,'GRC':11.07,'FRA':18.7,'DEU':21.25,'USA':30.58,'BRA':3.03,'COL':3.05,'JPN':17.19,'NZL':26.29,'PAK':0.35,'GHA':0.63,'CMR':0.45})

merged_gdeco_HDI_unpaiddomwork_df



merged_gdeco_HDI_unpaiddomwork_df[['GDP_per_capita','average_since_2000','HDI Rank (2021)','gd_ban','gd_hiring_ban','g_equal_pay_guarantee','gd_termination_ban','gd_ban_law', 'preg_discrimination_ban','gd_prevention_body','gd_policy_body','ml_paid', 'pl_paid','lowest_wage_replacement_paid_leave_mothers','ml_job_protection','ml_self_employed_paid','parental_leave_child_health', 'tuition_free_education_policy',' compulsory_education_policy','gd_ban_education']].corr()










# Now we will extract another dataset from OECD API called and after that, we will merge it with "merged_gdeco_HDI_unpaiddomwork_df"

# OECD API data extraction for the dataset: gender wage-gap

import requests
import xml.etree.ElementTree as ET # Library for parsing the XML data we get from the OECD API
import pandas as pd

# API URL with filters applied (countries selected)
url = "https://sdmx.oecd.org/public/rest/data/OECD.ELS.SAE,DSD_EARNINGS@GENDER_WAGE_GAP,1.0/NOR+NZL+BRA+COL+JPN+GRC+DEU+FRA+USA......_T?startPeriod=2005&endPeriod=2023&dimensionAtObservation=AllDimensions"

# Make the API request
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    print("Data retrieved successfully!")
else:
    print(f"Failed to retrieve data. Status code: {response.status_code}")


# Parse the XML content
root = ET.fromstring(response.content)

# Define the namespace to use with XML parsing
ns = {
    'generic': 'http://www.sdmx.org/resources/sdmxml/schemas/v2_1/data/generic',
    'message': 'http://www.sdmx.org/resources/sdmxml/schemas/v2_1/message'
}


# Find the DataSet element
# The DataSet element contains the actual data we need. Weâ€™ll find it using the appropriate namespace.
dataset = root.find('.//message:DataSet', ns)


# List to hold the extracted data
data = []

# Iterate over each Obs element in the DataSet
for obs in dataset.findall('generic:Obs', ns):
    obs_data = {}

    # Extract TIME_PERIOD, REF_AREA, GENDER from the ObsKey
    for value in obs.find('generic:ObsKey', ns):
        obs_data[value.attrib['id']] = value.attrib['value']

    # Extract the observation value
    obs_value = obs.find('generic:ObsValue', ns)
    if obs_value is not None:
        obs_data['OBS_VALUE'] = obs_value.attrib['value']
    else:
        print("ObsValue not found for an observation.")
        continue

    # Append the data
    data.append(obs_data)


# Check if data is being extracted
print(f"Number of records extracted: {len(data)}")
if len(data) > 0:
    print("Sample data:", data[:5])

    # Convert the list of dictionaries into a pandas DataFrame
    df = pd.DataFrame(data)

    # Display the first few rows of the DataFrame to check the data
    display(df.head())
else:
    print("No data extracted to save.")


# Save the DataFrame to a CSV file in the specified folder
df.to_csv('/Users/angela.garay/Ironhack/Week-3/Project/data/raw/gender_wage_gap_data.csv', index=False)

# Confirmation message
print("Data saved to '/Users/angela.garay/Ironhack/Week-3/Project/data/raw/gender_wage_gap_data.csv'")





import matplotlib.pyplot as plt

# Load the data from the folder
gender_wage_gap_df = pd.read_csv('/Users/angela.garay/Ironhack/Week-3/Project/data/raw/gender_wage_gap_data.csv')

gender_wage_gap_df.head(5)


# Filter the data for each country
country = 'FRA' # Here you can select the country you want to check

country_selected_df = gender_wage_gap_df[gender_wage_gap_df['REF_AREA'] == country]
country_selected_df.head(5)

# Pivot the DataFrame to have aggregation operation as the index and years as columns
country_selected_pivot = country_selected_df.pivot(
    index='AGGREGATION_OPERATION', 
    columns='TIME_PERIOD', 
    values='OBS_VALUE'
)
display(country_selected_pivot)


# Plot each 'AGGREGATION_OPERATION'(D1, MEDIAN, D9) over the years:

plt.plot(country_selected_pivot.columns, country_selected_pivot.loc['D1'], marker='o', color='red', label='(D1) Decile 1')
plt.plot(country_selected_pivot.columns, country_selected_pivot.loc['MEDIAN'], marker='o', color='blue', label='(MEDIAN) Median')
plt.plot(country_selected_pivot.columns, country_selected_pivot.loc['D9'], marker='o', color='purple', label='(D9) Decile 9')


# Customize the plot to match the style of the example
plt.title(f'GENDER WAGE GAP: {country}', fontsize=16)
plt.xlabel('Year', fontsize=14)
plt.ylabel('Percentage', fontsize=14)
plt.grid(True)

# Position the labels in the top-right corner
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))

# Show the plot
plt.show()





gender_wage_gap_df['REF_AREA'].unique()


gender_wage_gap_df['AGGREGATION_OPERATION'].unique()


# Cleaning the dataframe:
gender_wage_gap_df = gender_wage_gap_df.drop(columns=['UNIT_MEASURE', 'PAY_PERIOD', 'PRICE_BASE', 'SEX'])


gender_wage_gap_df.head()


# Create dataframe for the 2021 GDP data

# Mapping from country names to ISO 3-letter country codes
country_mapping = {
    'Norway': 'NOR',
    'Greece': 'GRC',
    'France': 'FRA',
    'Germany': 'DEU',
    'United States': 'USA',
    'Brazil': 'BRA',
    'Colombia': 'COL',
    'Japan': 'JPN',
    'New Zealand': 'NZL',
    'Pakistan': 'PAK',
    'Ghana': 'GHA',
    'Cameroon': 'CMR'
}

# GDP per capita data for 2021
gdp_per_capita_2021 = {
    'Country': ['NOR', 'GRC', 'FRA', 'DEU', 'USA', 'BRA', 'COL', 'JPN', 'NZL'],
    'GDP_per_Capita_2021': [36.5, 11.07, 18.7, 21.25, 30.58, 3.03, 3.05, 17.19, 26.29]
}

# Create the DataFrame
gdp_2021_df = pd.DataFrame(gdp_per_capita_2021)

display(gdp_2021_df)


# Filter gender_wage_gap_df for the year 2021 and selected countries

countries_of_interest = ['NOR', 'GRC', 'FRA', 'DEU', 'USA', 'BRA', 'COL', 'JPN', 'NZL']

wage_gap_2021 = gender_wage_gap_df[
    (gender_wage_gap_df['TIME_PERIOD'] == 2021) & 
    (gender_wage_gap_df['REF_AREA'].isin(countries_of_interest))
]

# Display the filtered DataFrame to check
display(wage_gap_2021.head())


# Pivot the dataframe to have AGGREGATION_OPERATION as columns
wage_gap_pivot_2021 = wage_gap_2021.pivot(
    index='REF_AREA', 
    columns='AGGREGATION_OPERATION', 
    values='OBS_VALUE'
)

# Display the pivoted DataFrame to ensure it's correct
display(wage_gap_pivot_2021.head())


# Merge the pivoted DataFrame with the GDP DataFrame
merged_2021_df = pd.merge(wage_gap_pivot_2021, gdp_2021_df, left_on='REF_AREA', right_on='Country')

# Display the merged DataFrame to ensure it's correct
display(merged_2021_df.head())


# Calculate correlations
correlation_d1 = merged_2021_df['D1'].corr(merged_2021_df['GDP_per_Capita_2021'])
correlation_d9 = merged_2021_df['D9'].corr(merged_2021_df['GDP_per_Capita_2021'])
correlation_median = merged_2021_df['MEDIAN'].corr(merged_2021_df['GDP_per_Capita_2021'])

# Print the correlation results
print(f"Correlation between D1 and GDP per Capita: {correlation_d1}")
print(f"Correlation between D9 and GDP per Capita: {correlation_d9}")
print(f"Correlation between Median and GDP per Capita: {correlation_median}")


# Create a scatterplot to see better the correlation


import seaborn as sns
import matplotlib.pyplot as plt

# Create a scatter plot using seaborn
plt.figure(figsize=(10, 6))
sns.scatterplot(x='GDP_per_Capita_2021', y='D1', data=merged_2021_df)

# Optionally add a regression line
sns.regplot(x='GDP_per_Capita_2021', y='D1', data=merged_2021_df, scatter=False, color='red', ci=None)

# Add labels and title
plt.title('Correlation between GDP per Capita (2021) and Wage Gap (D1)')
plt.xlabel('GDP per Capita (2021)')
plt.ylabel('Wage Gap (D1)')

# Display the plot
plt.grid(True)
plt.show()





display(merged_gdeco_HDI_unpaiddomwork_df)


display(wage_gap_pivot_2021)


# Reset index for wage_gap_pivot_2021 to bring REF_AREA as a column for merging
wage_gap_pivot_2021 = wage_gap_pivot_2021.reset_index()

# Perform the merge using 'REF_AREA' from wage_gap_pivot_2021 and 'country_code' from merged_gdeco_HDI_unpaiddomwork_df
# Use an outer join to ensure all countries from merged_gdeco_HDI_unpaiddomwork_df are included
final_merged_df = pd.merge(merged_gdeco_HDI_unpaiddomwork_df, wage_gap_pivot_2021, left_on='country_code', right_on='REF_AREA', how='left')

# Reorder columns to ensure D1, D9, and MEDIAN are at the end
columns_order = [col for col in final_merged_df.columns if col not in ['D1', 'D9', 'MEDIAN']] + ['D1', 'D9', 'MEDIAN']
final_merged_df = final_merged_df[columns_order]

# Display the final DataFrame to verify the results
display(final_merged_df)


# Rename the columns D1, D9, and MEDIAN:
final_merged_df = final_merged_df.rename(columns={
    'D1': 'wage-gap_D1',
    'D9': 'wage-gap_D9',
    'MEDIAN': 'wage-gap_median'
})

# Remove the REF_AREA column
final_merged_df = final_merged_df.drop(columns=['REF_AREA'])


display(final_merged_df)



